{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dfbb8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, LeakyReLU, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c75d9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(8*8*48, use_bias=False, input_shape=(100,)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU())\n",
    "\n",
    "generator.add(Reshape((8, 8, 48)))\n",
    "\n",
    "generator.add(Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU())\n",
    "\n",
    "generator.add(Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU())\n",
    "\n",
    "generator.add(Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=(64, 64, 3)))\n",
    "discriminator.add(LeakyReLU())\n",
    "\n",
    "discriminator.add(Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(LeakyReLU())\n",
    "\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "gan = Sequential()\n",
    "gan.add(generator)\n",
    "gan.add(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7592dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=(64, 64, 3)))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "discriminator.add(Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "discriminator.add(Conv2D(256, (4, 4), strides=(2, 2), padding='same'))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe055b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_output_shape = (64, 64, 1)\n",
    "# d_output = discriminator.layers[-2].output\n",
    "# d_output = Reshape(d_output_shape)(d_output)\n",
    "# # Define the GAN as a sequential model consisting of the generator followed by the discriminator\n",
    "# # Define the GAN model\n",
    "# gan_input = Input(shape=(100,))\n",
    "# gan_output = generator(gan_input)\n",
    "# gan_output = discriminator(gan_output)\n",
    "# gan_output = Concatenate()([gan_output, gan_input])\n",
    "# gan = Model(gan_input, gan_output)\n",
    "\n",
    "# gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "# gan = Sequential()\n",
    "# gan.add(generator)\n",
    "# gan.add(discriminator)\n",
    "\n",
    "# compile GAN model\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4565d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 882 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the labels and corresponding directories\n",
    "labels = ['Abdomen and Chest', 'Ankle', 'Cervical Spine','Elbow','Feet','Finger','Forearm','Hand','Hand and Wrist','Hip','Knee','Lower Leg','Lumbar Spine','Lumbar Spine and Thoracic Spine','Others','Pelvis','Shoulder','Sinus','Skull','Thoracic Spine','Wrist']\n",
    "dirs = ['E:/datanew/Abdomen and Chest','E:/datanew/Ankle','E:/datanew/Cervical Spine','E:/datanew/Elbow','E:/datanew/Feet','E:/datanew/Finger','E:/datanew/Forearm','E:/datanew/Hand','E:/datanew/Hand and Wrist','E:/datanew/Hip','E:/datanew/Knee','E:/datanew/Lower Leg','E:/datanew/Lumbar Spine','E:/datanew/Lumbar Spine and Thoracic Spine','E:/datanew/Others','E:/datanew/Pelvis','E:/datanew/Shoulder','E:/datanew/Sinus','E:/datanew/Skull','E:/datanew/Thoracic Spine','E:/datanew/Wrist', ]\n",
    "\n",
    "# Define the image data generator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datagen.flow_from_directory('E:/datanew', target_size=(256, 256), class_mode=None, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09613b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "4/4 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 256 and the array at index 1 has size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DD1E2~1.RHU\\AppData\\Local\\Temp/ipykernel_12096/456152537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Concatenate the real and fake images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mcombined_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Assign labels to the real and fake images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 256 and the array at index 1 has size 64"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "for epoch in range(100):\n",
    "    print(f'Epoch {epoch}')\n",
    "    \n",
    "    for batch in dataset:\n",
    "        # Generate a batch of fake images\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        fake_images = generator.predict(noise)\n",
    "\n",
    "        # Concatenate the real and fake images\n",
    "        combined_images = np.concatenate((batch, fake_images))\n",
    "\n",
    "        # Assign labels to the real and fake images\n",
    "        labels = np.concatenate((np.ones((batch_size, 1)), np.zeros((batch_size, 1))))\n",
    "\n",
    "        # Add noise to the labels\n",
    "        labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "        # Train the discriminator on the combined images and labels\n",
    "        discriminator_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "        # Generate a batch of noise vectors for the generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "        # Assign the labels for the fake images as ones\n",
    "        misleading_targets = np.ones((batch_size, 1))\n",
    "\n",
    "        # Train the generator on the noise with the misleading targets\n",
    "        gan_loss = gan.train_on_batch(noise, misleading_targets)\n",
    "\n",
    "    # Save the generator weights every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        generator.save_weights(f'generator_weights_epoch_{epoch}.h5')\n",
    "\n",
    "    # Generate and save new images for each label\n",
    "    for label, dir in zip(labels, dirs):\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        fake_images = generator.predict(noise)\n",
    "        for i in range(batch_size):\n",
    "            img = array_to_img(fake_images[i] * 255., scale=False)\n",
    "            img.save(os.path.join(dir, f'{label}_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad1802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
